# Memory Management

## Overview of Memory Types

### Cache
![Cache](/images/cache_levels.png)

#### L1 Cache
- Fastest and smallest memory type, usually in 16 - 64 kB range
- Separated into **instruction** (L1i) and **data** (L1d)
- grows in importance with increased speed of CPU
- *Avoids delays in data transmission and helps to make optimum use of CPU's capacity.*

#### L2 Cache
- located close to the CPU and has direct connection
- information between L2 and CPU is managed by L2 controller
- size usually < 2 MB
- Choosing between a processor with more clock speed or a larger L2 cache
    - higher clock speed => individual programs run faster
    - larger cache => several programs run simultaneously

#### L3 Cache
- Shared amongst all cores (multicore processor)
- [Cache Coherence Protocol (CCP)](https://en.wikipedia.org/wiki/Cache_coherence) can run much faster
   - Compares cache of all cores to maintain data consistency so everyone has access to all the data at the same time
- Intended to simplify and accelerate the CCP and data exchange between cores

### Temporal & Spacial Locality
Rough overview of the latency of various memory operations. Values might change based on system but the order of magnitude will be similar.
![Cache Locality](/images/cache_locality.png)
Originally from Peter Norvig: http://norvig.com/21-days.html#answers

#### Temporal Locality
- Over time the same memory address is accessed frequently (eg. in a loop)
- Keeps memory areas accessible as quickly as possible

#### Spatial Locality
- After an access to an address range, the next access to an address in the immediate vicinity is highly probable (e.g. in arrays)
- exploited by moving the adjacent address areas upwards into the next hierarchy level during a memory access.

```C++
#include <chrono>
#include <iostream>

int main()
{
    // create array
    const int size = 4;
    static int x[size][size];

    auto t1 = std::chrono::high_resolution_clock::now();
    for (int i = 0; i < size; i++)
    {
        for (int j = 0; j < size; j++)
        {
            x[j][i] = i + j;
            std::cout << &x[j][i] << ": i=" << i << ", j=" << j << std::endl;
        }
    }

    // print execution time to console
    auto t2 = std::chrono::high_resolution_clock::now(); // stop time measurement
    auto duration = std::chrono::duration_cast<std::chrono::microseconds>(t2 - t1).count();
    std::cout << "Execution time: " << duration << " microseconds" << std::endl;

    return 0;
}
```
Code example provided by: Udacity C++ Nanodegree

#### Commands to Try
```bash
# MAC OS
sysctl -a hw

# Debian Linux
lscpu | grep Cache
```

### Virtual Memory
- Virtual memory is a very useful concept in computer architecture because it helps with making your software work well given the configuration of the respective hardware on the computer it is running on.
- In a nutshell, virtual memory guarantees us a fixed-size address space which is largely independent of the system configuration. Also, the OS guarantees that the virtual address spaces of different programs do not interfere with each other.
- The task of mapping addresses and of providing each program with its own virtual address space is performed entirely by the operating system, so from a programmer’s perspective, we usually don’t have to bother much about memory that is being used by other processes.
- Two important terms which are often used in the context of caches and virtual memory:
   - Memory Page: number of successive memory locations in a virtual memory defined by the computer architecture and the OS.
   - Memory Frame: Same as memory page but is located in the physical memory space and **NOT** the virtual memory space.
   ![Virtual Memory](/images/virtual_memory.png)
   Image by *Udacity C++ Nanodegree*

   As can be seen, both processes have their own virtual memory space. Some of the pages are mapped to frames in the physical memory and some are not. If process 1 needs to use memory in the memory page that starts at address 0x1000, a page fault will occur if the required data is not there. The memory page will then be mapped to a vacant memory frame in physical memory. Also, note that the virtual memory addresses are not the same as the physical addresses. The first memory page of process 1, which starts at the virtual address 0x0000, is mapped to a memory frame that starts at the physical address 0x2000.

   > Relocating virtual swap file to a SSD Location would help with performance.

## Variables and Memory
### The Process Memory Model
![Process Model](/images/virtual_process_model.png)
Image by *Udacity C++ Nanodegree*

We are unable to use the entire address space.
- Non-usable blocks
  - OS Kernel Space and Text are reserved for the OS
    - In **kernel space** only code trusted is executed, maintained by the OS & serves as an interface between the user code and system kernel
    - In **text space** holds code generated by the compiler and linker
- Usable blocks
  - **stack**: a contiguous memory block of fixed size ([see code example stackOverflow.cpp](stackOverflow.cpp))
  - **heap**: memory space where data with dynamic storage lives
  - **Block Started by Symbol (BSS)**: used in many compilers and linkers, contains global and static variables that are initialized with zero values i.e. arrays that are not initialized with predefined values
  - Memory for variables in segment is allocated once when a program is run and persists through its lifetime
  - **Data**: this segments is similar to *BSS* with major difference being that variables in this segment have non-zero initialized values.
  - Memory for variables in segment is allocated once when a program is run and persists through its lifetime


  | STACK MEMORY | HEAP MEMORY |
  | :---: | :---: |
  | automatically allocated | dynamically allocated |
  | fixed memory size | theoretically no size limitations (limited by available memory) |
  | variables are allocated at compile-time | variables are allocated at run-time |
  | stores local variables & function inputs/outputs | |
  | very efficient since managed by OS | computationally more expensive than stack |
  | OS automatically manages memory | programmer has to manage memory using *malloc/free* or *new/delete* |
  | thread-safe, each thread has dedicated stack | shared between threads, need to account for concurrency |
  | limited scope based on entry/exit | scope available until address is known |
  | stack memory is sequential therefore easy and secure | heap allocation/deallocations can occur arbitrarily therefore memory is fragmented overtime making it more difficult and expensive to manage. |
  > - Decision between stack and heap comes down to application. Based on the application programmer must pick the best suited space and know the advantages & disadvantages.
  > - By default **stack** should be the choice of memory since access is usually faster making memory management easier than the heap but has limited space and variables will only get deallocated when out of scope
  > - **heap** is better suited when large memory storage is required i.e. images/videos etc. However, programmer needs to carefully manage memory, if not managed correctly it can lead to memory leaks or dangling pointers.

### Memory Allocation C++
- Types of memory Allocation
  - Static Memory Allocation
    - performed for static and global variables
    - memory persists for lifetime of program
  - Automatic Memory Allocation
    - performed for functions parameters and local variables
    - stored on the **stack**
    - limited scope based on enter/exit
  - Dynamic Memory Allocation
    - way for programs to request memory from the OS at runtime as needed
    - performed on the **heap** and only limited by the size of the address space

## Dynamic Memory Allocation (The Heap)
### Using malloc and free
**Allocating Dynamic Memory on the heap**
There are two ways of allocating contiguous block of memory on the heap. *If the space is insufficient, returns NULL pointer.*
1. ```malloc``` is used to dynamically allocate a single large block of memory
```C++
pointer_name = (cast-type*) malloc(size);
```
2. ```calloc``` is used to dynamically allocate the specified number of blocks of memory of the specified type. Each block is initialized to zero.
```C++
pointer_name = (cast-type*) calloc(num_elems, size_elems);
```
3. ```realloc``` can be used to grow memory size without overwriting data
```C++
pointer_name = (cast-type*) realloc(pointer_name, new_size);
```
4. ```free``` is used to free up allocated memory ```free(pointer_name)```
  - can only release memory that was reserved by ```malloc``` or ```calloc```
  - can only release memory that hasn't been released before. Releasing same block of memory twice will result in error.

### Using new and delete
- ```new/delete are operators``` while ```malloc/calloc/realloc/free are functions``` this allows operator overloading for ```new/delete```
- new/delete are the object-oriented counterpart to memory management with malloc/free
#### Major differences between malloc/free and new/delete
- new/delete call the constructor/destructor while malloc/free don't
- ```malloc``` returns a ```void``` which needs to be type -casted
```C++
// Malloc example
MyObject *p_malloc = (MyObject*)malloc(sizeof(int));
// cleanup of memory allocated using "malloc"
free(p_malloc);
// "new" syntax - returns correct type automatically - it is type-safe
MyObject *p_new = new MyObject();
// cleanup of memory allocated using "new"
delete p_new;
```
##### Optimizing Performance with placement new
Separating allocation from construction can significantly improve performance. This can be done using ```placement new``` syntax as follows
```C++
void *memory = malloc(size of MyClass));
MyClass *object = new (memory); // placement new
MyClass;
//deleting "placement new" memory
object->~MyClass();
free(memory);
```
##### Reasons for overloading ```new``` and ```delete```
1. Overloaded new operator functions allows to add additional parameters giving programmer more flexibility in customizing the memory allocation for objects.
2. Provides an easy way to integrate a mechanism similar to garbage collections (such as java)
3. Code can be made more robust by adding exception handling capabilities into ```new/delete```
4. It is easy to add customized behavior, ex. overwriting deallocated memory with zeros to improve security of critical application data

### Typical Memory management problems
| Operating System | Debugging Tools | Example command |
| :--- | :--- | :--- |
| Linux/MacOS | [Valgrind](https://valgrind.org/) | ```valgrind --leak-check=full --show-leak-kinds=all --track-origins=yes --verbose --log-file=./bin/valgrind-out.txt <cpp_executable_filename>``` |
| Windows | [Visual Studio](https://visualstudio.microsoft.com/downloads/) and [C Run-time Library (CRT)](https://learn.microsoft.com/en-us/visualstudio/debugger/finding-memory-leaks-using-the-crt-library?view=vs-2019) | |

1. Memory leaks
  - occur when data is allocated in the heap at runtime but not properly deallocated.
  - program that forgets to clear a memory block is said to have a memory leaks
  - if a program runs for a short time, memory leaks are not a significant problem
  - memory leaks are a problem when a program has a long runtime or uses a large data structure, this can fill the heap causing a program crash
2. Buffer overruns
  - occur when memory outside the allocated limits is overwritten.
  - this effect may not be visible immediately
  - sometimes leads to injecting malicious code into program
3. Uninitialized memory
  - based on the compiler data structures sometimes are not initialized, this can cause issues since there might be garbage values in that memory location
  - Generally variable will be automatically initialized if
    - the default constructor initializes all primitive types
    - array initializer syntax is used int ```a[10] = {};```
    - it is a global or extern variable
    - it is defined as ```static```
4. Incorrect pairing of allocation and deallocation
  - freeing block of memory more than once
  - freeing block of memory that has not been allocated
  - using ```malloc() & delete``` or ```new & free()``` can also cause improper pairings
5. Invalid Memory Access
  - Occurs when trying to access a block of heap memory that has not yet or has been deallocated

## Resource Copying Policies
### Copy semantics
- Default assignment operator creates a duplicate copy of all the member variables inside the object
- Default behavior of both the ```copy constructor``` and ```assignment operator``` is to perform a **shallow copy**

![Shallow Copy](/images/resourceCopy_shallowCopy.png)

- Different Copy Policies
1. Default copying
2. No Copying
3. Exclusive ownership
4. Deep copying
5. Shared Ownership

#### Default Copy - Copy Semantics Code provided by Udacity C++ Nanodegree
```C++
#include <iostream>

class MyClass
{
private:
    int *_myInt;
public:
    MyClass()
    {
        _myInt = (int *)malloc(sizeof(int));
    };
    ~MyClass()
    {
        free(_myInt);
    };
    void printOwnAddress() { std::cout << "Own address on the stack is " << this << std::endl; }
    void printMemberAddress() { std::cout << "Managing memory block on the heap at " << _myInt << std::endl; }
};
int main()
{
    // instantiate object 1
    MyClass myClass1;
    myClass1.printOwnAddress();
    myClass1.printMemberAddress();

    // copy object 1 into object 2
    MyClass myClass2(myClass1); // default copy constructor - shallow copy
    myClass2.printOwnAddress();
    myClass2.printMemberAddress();

    return 0;
}
```

#### NoCopy Policy - Copy Semantics Code provided by Udacity C++ Nanodegree
- This is the simplest policy in which all copying and assignment is forbidden.
- This is achieved by declaring but not defining a private copy constructor (see ```NoCopyClass1```) and assignment operator or alternatively by making both public and assigning the ```delete``` operator (see ```NoCopyClass2```).
- On compiling the code will generate an error which indicates that both cases effectively prevent the original object from being copied/assigned.

```C++
class NoCopyClass1
{
private:
    NoCopyClass1(const NoCopyClass1 &);
    NoCopyClass1 &operator=(const NoCopyClass1 &);

public:
    NoCopyClass1(){};
};
class NoCopyClass2
{
public:
    NoCopyClass2(){}
    NoCopyClass2(const NoCopyClass2 &) = delete;
    NoCopyClass2 &operator=(const NoCopyClass2 &) = delete;
};
int main()
{
    NoCopyClass1 original1;
    NoCopyClass1 copy1a(original1); // copy c’tor
    NoCopyClass1 copy1b = original1; // assigment operator

    NoCopyClass2 original2;
    NoCopyClass2 copy2a(original2); // copy c’tor
    NoCopyClass2 copy2b = original2; // assigment operator

    return 0;
}
```
#### NoCopy Policy - Copy Semantics Code provided by Udacity C++ Nanodegree


### Lvalues and Rvalues
### Move semantics
### Using move semantics

## Smart Pointers
### Resource Acquisition is Initialization (RAII)
### Smart Pointers
### Transferring ownership
### Importance of Scope
